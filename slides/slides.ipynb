{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%config IPCompleter.greedy=True\n",
    "# load libraries and set plot parameters\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('pdf', 'png')\n",
    "plt.rcParams['savefig.dpi'] = 75\n",
    "\n",
    "plt.rcParams['figure.autolayout'] = False\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['lines.linewidth'] = 2.0\n",
    "plt.rcParams['lines.markersize'] = 8\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['font.family'] = \"serif\"\n",
    "plt.rcParams['font.serif'] = \"cm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "- GMM\n",
    "    - kmeans + gmm(https://ipvs.informatik.uni-stuttgart.de/mlr/marc/teaching/19-MachineLearning/06-unsupervised.pdf)\n",
    "    - kmeans implementation (https://www.kaggle.com/andyxie/k-means-clustering-implementation-in-python)\n",
    "- HMM\n",
    "    - hmm theoretical (https://ipvs.informatik.uni-stuttgart.de/mlr/marc/teaching/18-ArtificialIntelligence/09-graphicalModels.pdf)\n",
    "    - hmm implementation heads + tails (https://github.com/ananthpn/pyhmm)\n",
    "    - cont time and discrete time plots (https://github.com/lopatovsky/HMMs)\n",
    "    - hmm robo filtering (https://github.com/beneisnr/hMm-filtering)\n",
    "- DTW\n",
    "\n",
    "- pbdlib\n",
    "    - Related Work:\n",
    "    - no symbolic approach (look up \"Natural methods for robot task learning: Instructive demonstrations, generalization and practice\")\n",
    "        - DRAWBACK: symbolic approaches rely on biases to be segmented\n",
    "    - no direct time dependence\n",
    "        - DRAWBACK: Algining and scaling time dependet sequences is a difficult task (handling spatial and temporal perturbances is hard)\n",
    "    - other approaches have considererd modeling the intrinsic dynamics of motion\n",
    "        - BENEFIT: does not depent on explicit time variable\n",
    "        - BENEFIT: can be modulated in unseen regions\n",
    "        - DRAWBACK: require high number of states and smooting procedure\n",
    "    - propsed model: HMMs and GMMs\n",
    "    - GMR models joint probability function of the data (no direct regression like gpr)\n",
    "    - regression function is then derived from the joint density model\n",
    "        - ADVANTAGE: input and output components are only specified at the very last step of the process\n",
    "        - ADVANTAGE: density estimation can be learning in an off-line phase, regression process can be computed very rapidly\n",
    "        - ADVANTAGE: can handle different sources of missing data: system can consider any combination of input/output mappings\n",
    "\n",
    "- do PCA\n",
    "\n",
    "## Approach\n",
    "\n",
    "- a skill is demonstrated to the robot in slightly different situations\n",
    "- demonstration $m \\in \\{1, ..., M\\}$ consists of a set of Trajectories $T_m$\n",
    "- Trajectory $T_m$ consists of $d$-dimensional joint positions $x$ and velocities $\\dot{x}$ \n",
    "\n",
    "$$D = \\{\\{(x_t, \\dot{x}_t)\\}_{t=1}^T\\}_{m=1}^M$$\n",
    "\n",
    "- joint distribution $\\mathcal{P}(x, \\dot{x})$ is encoded in a continuous HMM of K states.\n",
    "- output distribution of each state is represented by a gaussian which encodes local variation and correlation information\n",
    "- Parameters of HMM:\n",
    "\n",
    "$$\\{\\Pi, a, \\mu, \\Sigma\\}$$\n",
    "\n",
    "- learned using Baum-Welch Algorithm(variant of the expectation maximization algorithm)\n",
    "- Input and output components of HMM in each state $s_i$:\n",
    "\n",
    "$$\\mu_i = \\left[\\begin{array}{c}\\mu_i^x \\\\ \\mu_i^{\\dot{x}}\\end{array}\\right] \\text{, } \\Sigma_i = \\left[\\begin{array}{cc}\\Sigma_i^x & \\Sigma_i^{x\\dot{x}}\\\\ \\Sigma_i^{\\dot{x}x}& \\Sigma_i^{\\dot{x}}\\end{array}\\right] $$\n",
    "\n",
    "- given the current position command, a desired velocity command is estimated using gaussian mixture regression\n",
    "\n",
    "$$\\hat{\\dot{x}} = \\sum_{i=1}^K h_i(x) [ \\mu_i^{\\dot{x}} + \\Sigma_i^{\\dot{x}x}(\\Sigma_i^x)^{-1} (x - \\mu_i^x)]$$\n",
    "\n",
    "- where $h_i(x)$ is used to encode the sequential information encapsulated in the HMM:\n",
    "\n",
    "$$h_i(x_t) = \\frac{(\\sum_{j=1}^K h_j(x_{t-1}) a_{ji}) \\mathcal{N}(x_t; \\mu_i^x, \\Sigma_i^x)}{\\sum_{k=1}^K [(\\sum_{j=1}^K h_j(x_{t-1}) a_{jk})\\mathcal{N}(x_t; \\mu_k^x, \\Sigma_k^x)]}$$\n",
    "\n",
    "- since reproduction is unstable in regions that have not been covered during the demonstration, a secondary term has to be added:\n",
    "\n",
    "$$\\hat{x} = \\sum_{i=1}^K h_i(x) [ \\mu_i^{x} + \\Sigma_i^{x\\dot{x}}(\\Sigma_i^\\dot{x})^{-1} (\\dot{x} - \\mu_i^\\dot{x})]$$\n",
    "\n",
    "\n",
    "$$\\ddot{x} = (\\hat{\\dot{x}} - \\dot{x}) \\kappa^{\\mathcal{V}} + (\\hat{x}-x)\\kappa^{\\mathcal{P}} $$\n",
    "\n",
    "- show plots\n",
    "\n",
    "- the first term allows the robot to follow the demonstrate motion profile, the second term keeps the robot from departing from a known situation and forces it to com back into the subspace of demonstrations\n",
    "\n",
    "- may lead to oscilations\n",
    "\n",
    "- use adaptive gains: proportional gain should decrease when the system is close to the demonstrated trajectories\n",
    "\n",
    "- adaptive gains allow the controller to focus on the other constraints of the task\n",
    "\n",
    "## Metrics\n",
    "\n",
    "- M1: RMS error along the motion w.r.t to the demonstration dataset  M_1\n",
    "\n",
    "- M2: RMS error after DTW; spatial information is prioritized here M_2; the metric compares the path followed by the robot instead of the exact trajectory\n",
    "\n",
    "- M3: Norm of jerk; derivative of acceleration is a good candidate to evaluate the smoothness of human motion\n",
    "\n",
    "- M4: Computation time of learning process\n",
    "\n",
    "- M5: Retrieval duration\n",
    "\n",
    "\n",
    "## Comparison\n",
    "\n",
    "- HMM vs TMGR (Time dependent gaussian mixture regression): \n",
    "\n",
    "- M1 & M2: all methods perform well, HMM performs well with a small number of states\n",
    "\n",
    "- M3: HMM is a little bit jerky\n",
    "\n",
    "- M4: training time is less important than reproduction time\n",
    "\n",
    "- M5: LWR not competitable; linear dependencs in the number of states\n",
    "\n",
    "- when dimensionality is low, the difficulty is to correctly handle the crossing points that can appear when randomly generating trajectories\n",
    "\n",
    "## Results\n",
    "\n",
    "- HMM can handle crossing points in trajectories (due to sequential information)\n",
    "\n",
    "- HMM can be used in an unsupervised manner: several movements can be encoded in a single model without specifying any class label or number of movements\n",
    "\n",
    "- HMM hitting a table tennis ball from different angles, desired velocity is encoded in demonstrations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
